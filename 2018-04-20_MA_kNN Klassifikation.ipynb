{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy learning: Klassifikation mit k nächsten Nachbarn (kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Die folgenden Darstellung und Abbildungen basieren sofern nicht anders angegeben auf Kapitel 3 \"Lazy Learning\" aus dem Buch [\"Machine Learning with R\"](https://www.packtpub.com/packt/free-ebook/r-machine-learning) von Brett Lanz entnommen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Idee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein großer Bereich des maschinellen Lernens bilden die Klassifikationen. Mit Hilfe dieses Algorithmus' sollen Daten in eine bestimmte Klasse **`Anmerkung(1): \"eingeteilt\" falsch geschrieben:`** eingteilt werden.  Der kNN - Algorithmus ist parameterfrei, d.h. es muss  keine Annahme über die Verteilung der zugrundeliegenden Daten gemacht werden.\n",
    "Bei diesem Verfahren wird der Abstand der vorliegenden Daten eines Objekts zu den k nächsten Nachbarn gemessen und der Kategorie mit den meisten nächsten Nachbarn zugeordnet.  \n",
    "Zur Veranschaulichung dient folgende Abbildung: die blauen Punkte sind Premiumkunden und die grünen Punkte Nicht - Premiumkunden. Die y - Achse repräsentiert das umgesetzte Geld und die x - Achse die Anzahl an Käufen. Nun gilt es beispielsweise herauszufinden, ob es sich lohnt, für den Kunden mit dem Fragezeichen Werbung für das Premiumangebot zu schalten. \n",
    "\n",
    "\n",
    "<!---\n",
    "![Beispielbild kNN](img/img1.png)\n",
    "--->\n",
    "<img src=\"img/img1.png\" width=\"500\">  <center> *Quelle Blog von David Benjamin Hentschel [Link](https://www.david-benjamin-hentschel.de/klassifikation-mit-dem-k-naechste-nachbarn-algorithmus/)*</center>\n",
    "\n",
    "Wenn nun k=3 festgelegt wird, dann wird der Abstand zu den drei naheliegensten Nachbarn betrachtet. In diesem Fall gibt es zwei nächste Nachbarn, die Premium - Kunden sind, deshalb würde man auch diesen Kunden als Premium einstufen und ihm Werbung senden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ein Beispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch **`Anmerkung(2): \"beim\" falsch geschrieben:`** bim kNN - Algorithmus wird der Gesamtdatensatz in zwei Teile aufgeteilt:\n",
    "- einen Trainingsdatensatz und \n",
    "- einen Lerndatensatz\n",
    "\n",
    "\n",
    "**Der Trainingsdatensatz** besteht aus Beispielen, die alle bereits in Klassen eingeteilt sind, indem eine zusätzliche Spalte mit Angabe der Klasse begefügt ist. **Der Testdatensatz** hat die Variable, die die Klasse angibt nicht, ansonsten ist er gleich.  \n",
    "Die einzelnen Merkmale werden vom kNN - Algorithmus wie Koordinaten in einem mehrdimensionalen Koordinatensystem behandelt. Um sich dies besser vorstellen zu können, werden im folgenden Beispiel nur zwei Merkmale verwendet, sodass es zwei Dimensionen (eine x-Achse und eine y-Achse) gibt. Das erste Merkmal gibt in einem Intervall von 1-10 an, wie knusprig ein Lebensmittel ist. Das zweite Merkmal gibt an, wie süß ein Lebensmittel ist. Außerdem hat jedes Lebensmittel eine der drei Klassen:\n",
    "- Obst (fruit)\n",
    "- Gemüse (vegetable)\n",
    "- Proteine (protein)\n",
    "\n",
    "<!---\n",
    "![Tabelle kNN](img/knn_img2.png)\n",
    "--->\n",
    "<img src=\"img/knn_img2.png\" width=\"500\">\n",
    "\n",
    "\n",
    "Diese Tabelle würde als Streudiagramm wie folgt aussehen:\n",
    "\n",
    "<!---\n",
    "![Streudiagramm kNN](img/knn_img3.png)\n",
    "--->\n",
    "<img src=\"img/knn_img3.png\" width=\"500\">\n",
    "\n",
    "\n",
    "Daraus ist leicht das Muster zu erkennen: Ähnliche Lebensmittelarten tendieren dazu, sich nahe beieinander zu gruppieren.  \n",
    " \n",
    "Nun soll noch eine Tomate klassifiziert werden. Die uralte Frage \"Ist die Tomate ein Obst oder ein Gemüse?\" soll mit diesem Alogrithmus beantwortet werden.\n",
    "\n",
    "\n",
    "<!---\n",
    "![Klassifikation Tomate kNN](img/knn_img4.png)\n",
    "--->\n",
    "<img src=\"img/knn_img4.png\" width=\"500\">\n",
    "\n",
    "Hier ist k = 4. Die Tomate wird den Früchten zugeordnet, da zwei ihrer nächsten Nachbarn zu den Früchten gehören. Von den anderen beiden Kategorien gibt es jeweils nur einen nächsten Nachbarn.\n",
    "\n",
    "> *Anmerkung*: Tomaten gelten laut [Experten](http://www.tomaten-welt.de/wissenswertes/faq/sind-tomaten-obst-oder-gemuese/) als Fruchtgemüse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Berechnung des Abstands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die nächsten Nachbarn der Tomate zu finden, bedarf es einer Abstandsfunktion. Es gibt verschiedene Möglichkeiten, den Abstand zu berechnen. Klassicherweise verwendet der kNN - Algorithmus den **Euklidische Abstand**. Dieser ist gut in der letzten Abbilung zu erkennen, wo von der Tomate aus eine gerade Linie zu den nächsten Nachbarn gestrichelt ist.  \n",
    "Der Euklidische Abstand ist durch folgende Formel aufgeführt. Wobei $p$ und $q$ die beiden Objekte sind, zwischen denen der Abstand gemessen werden soll; sie haben jeweils $n$ Merkmale. $p_1$ ist der erste Merkmalswert von p (also in unserem Beispiel die Süße der Tomate) und $q_1$ ist der erste Merkmalswert von q (bei uns die Süße der Orange bspw).  \n",
    "\n",
    "  \n",
    "  $$\n",
    "  dist(p,q) = \\sqrt{(p_1 - q_1)^2+(p_2 - q_2)^2...+(p_n - q_n)^2}\n",
    "  $$\n",
    "  \n",
    "\n",
    "Es wird jedes Merkmal vergleichen. Wenn der Abstand der Tomate (sweetness=6, crunchiness = 4) zur grünen Bohne (sweetness=3, crunchiness = 7) berechnet wird, sieht die Formel also so aus: \n",
    "\n",
    "$$\n",
    "dist(tomato,green bean) = \\sqrt{(6 - 3)^2+(4 - 7)^2} = 4.2\n",
    "$$\n",
    "\n",
    "Folgende Tabelle zeigt den Abstand der Tomate von einigen ihrer Nachbarn\n",
    "\n",
    "   ingridient | sweetness | crunchiness | food type |  distance to tomato  | \n",
    "  :----------:|:---------:|:-----------:|:---------:| :------------------: |\n",
    "    grape     |     8     |      5      |   fruit   |      2.2             |       \n",
    "  green bean  |     3     |      7      | vegetable |      4.2             | \n",
    "     nuts     |     3     |      6      |  protein  |      3.6             |\n",
    "    orange    |     7     |      3      |   fruit   |      1.4             |\n",
    "    \n",
    "Bei einer 1NN - Klassifikation (k=1) wäre die Orange der nächste Nachbar, da der Abstand zu ihr der kleinste ist (=1.4) und die Tomate würde daher als Obst klassifiziert werden. Bei k = 3 wird eine Abstimmung (engl. vote) unter den drei nächsten Nachbarn (Orange, Trauben, Nüsse) durchgeführt. Weil die Mehrheit der nächsten Nachbarn zum Obst gehört (2 von 3), wird die Tomate wieder als Frucht klassifiziert.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Wahl für ein angemessenes k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist entscheident wie man k wählt, denn es bestimmt wie gut ein Modell verallgemeinert werden kann.  \n",
    "Ein großes k reduziert den Einfluss von verrauschten Daten, kann jedoch das Modell so verzerren, dass kleine, aber wichtige Muster übersehen werden. Wenn beispielsweise k so groß gesetzt wird wie die Anzahl der Beobachtungen, dann wäre jede Instanz bei der Abstimmung repräsentiert und das Modell würde immer die Klasse, in der am meisten Instanzen repräsentiert sind, vorhersagen.  \n",
    "Das entgegengesetzte Extrem, wenn also k=1 gesetzt wird, hat zur Folge, dass verrauschte Daten oder Ausreißer zu starken Einfluss auf die Vorhersage haben. \n",
    "\n",
    "<!---\n",
    "![Klassifikation Tomate kNN](img/knn_img6.png)\n",
    "--->\n",
    "<img src=\"img/knn_img6.png\" width=\"500\">\n",
    "<center> *Quelle:Universität München* [Link](http://www.dbs.informatik.uni-muenchen.de/Lehre/KDD/WS0304/Skript/kdd-3-klassifikation2.pdf) </center>\n",
    "\n",
    "Das beste k ist wohl zwischen diesen beiden Extremen. Die folgende Abbildung zeigt wie die Entscheidungsgrenze von einem größeren bzw kleineren k beeinflust wird. Ein kleineres k ermöglicht komplexere Entscheidungen. Das Problem ist, dass man nicht weiß, ob die gerade oder die kurvige Linie das zugrundeliegende Konzept repräsentiert.\n",
    "\n",
    "<!---\n",
    "![Klassifikation Tomate kNN](img/knn_img4.png)\n",
    "--->\n",
    "<img src=\"img/knn_img5.png\" width=\"500\">\n",
    "\n",
    "\n",
    "In der Praxis hängt die Wahl von k von der Schwere des zu lernenden Modells und der Anzahl der Trainingsdaten ab. Eine übliche Vorgehensweise ist, dass man die Quadratwurzel von den Anzahl der Trainingsdaten nimmt.  \n",
    "\n",
    "In unserem Beispiel:\n",
    "\n",
    " $$\n",
    "  k = \\sqrt{n} = \\sqrt{15} = 3.87\n",
    "  $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Es ist jedoch nicht immer die beste Regel. Manchmal werden verschiedene k getestet und am Ende das gewählt, das die beste Klassifikation liefert. Bei großen Datensätze, die rerästentativer sind, ist die Wahl von k nicht so entscheident. Denn selbst feine Muster haben genügend **`Anmerkung(3): \"Repräsentanten\" falsch geschrieben:`** Repräsentaten in einer Klasse, die die nächste Nachbarn sein können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten für die Klassifikation aufbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor der kNN - Algorithmus angewandt wird, werden die Ausprägungen der Merkmale in ein Standard - Intervall transformiert. Denn große Werte wären bei der Abstandsmessung dominant. Im oberen Beispiel ist das kein Problem, da unsere beiden Werte (sweetness und crunchiness) beide auf einer Skala von 1 bis 10 gemessen wurden.\n",
    "\n",
    "Angenommen, wir hätten ein zusätzliches Merkmal \"Schärfe\" (spiciness) in der Scoville - Skala. Diese Skala wird standardmäßig für die Einstufung von Schärfe verwendet und reicht von 0 (nicht scharf) is zu über eine Million (für die schärfste Chili). Die Differenz von nicht - **`Anmerkung(4): \"scharf\" statt schaft:`** schaft und scharf kann bis über eine Million sein, während die Differenz der Süße höchstens 10 sein kann. Deshalb könnte die Klassifizierung nur anhand der Schärfe durchgeführt werden, da der Einfluss von Süße und Knusprigkeit zu gering ist.\n",
    "\n",
    "Deshalb müssen die Daten in ein **`Anmerkung(5): \"EinheitsinTERvall\":`** Einheitsinverall transformiert werden. Dazu gibt es unterschiedliche Wege."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Die min-max - Transformation (Normalisierung)**\n",
    "\n",
    "Bei der min-max - Transformation werden alle Werte in ein Intervall von 0 bis 1 transformiert.  Von jedem Merkmalswert wird das Minimum diesen Wertes abgezogen und durch den Range geteilt.\n",
    "\n",
    "$$\n",
    "x_{neu} = \\frac{x - min(x)}{max(x) - min(x)}\n",
    "$$\n",
    "\n",
    "Normalisierte Merkmale können auch als Prozentzahl von 0 bis 100 betrachtet werden. Ihr Wert gibt an wo er zwischen dem ursprünglichen Minimum (0%) und Maximum (100%) lag. \n",
    "\n",
    "**Die z-Transformation (z-score - Standardisierung)**\n",
    "\n",
    "Bei der z - Transformation wird **`Anmerkung(6): zu viel \"der\":`** der der Mittelwert vom Merkmalswert abgezogen und durch die Standardabweichung geteilt. Diese Transformation, die sich an Eigenschaften der **`Anmerkung(7): \"Normalverteilung\":`** Noramlverteilung anlehnt, gibt an, wie viele Standardabweichungen der ursprüngliche Wert über oder unter den Mittelwert fiel.\n",
    "\n",
    "$$\n",
    "x_{neu} = \\frac{x - \\mu}{\\sigma} x_{neu} = \\frac{x - mean(x)}{StdDev(x)} \n",
    "$$\n",
    "\n",
    "**Dummy - Variablen**\n",
    "\n",
    "Für nominale Merkmale (Bsp. Geschlecht) kann der Euklidische Abstand nicht berechnet werden. Deshalb müssen sie als numerische Variablen codiert werden. Bspw. gibt 0 eine Kategorie an (z.B. weiblich) und 1 die andere Kategorie (z.B. männlich). Die Codierung für eine **`Anmerkung(8): \"GeschLEchtsvariable:`** Geschelchtsvariable **`Anmerkung(9): \"könnte\"?`** könnt so aussehen:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "   male =\n",
    "   \\begin{cases}\n",
    "    1 & \\text{, für x = männlich} \\\\\n",
    "    0 & \\text {, für alle anderen Fälle} \\\\\n",
    "   \\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Wie codiert wird, wenn es bei einer Variablen mehr als zwei Kategorien gibt, können Sie [hier](https://de.wikipedia.org/wiki/Dummy-Variable) nachlesen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warum ist der kNN Algorithmus träge (lazy)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klassifikationen, die auf nächsten Nachbarn beruhen, werden als träge bezeichnet, weil keine Abstraktion stattfindet. Der Abstraktions- und der Generalisierungsprozess werden übersprungen, was eigentlich die Definition von Maschinellem Lernen untergräbt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brustkrebstdiagnose  mit Hilfe des kNN - Algorithmus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Daten erfassen**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir nehmen einen Datensatz \"Breast Cancer Wisconsin Diagnostic\" als Datensatz, der von Wissenschaftler der Universität in Wisconsin bereitgestellt wurde ([Downloadlink Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/)). Er umfasst 569 Beobachtungen mit je 32 Variablen. Eine Variable ist eine ID, eine andere enthält die Klasse \"Diagnose\" mit den Ausprägungen M (maligant) für bösartig und B (benign) für gutartig. Die weiteren 30 Variablen sind numerisch und kommen von Labormessungen. Dabei wurden der Mittelwert (mean), Standardfehler (se) und der schlechteste Wert (worst) (also der Höchste) von 10 verschiedene Eigenschaften des Zellkerns festgehalten. Die Ergebnisse der Labormessungen bestimmen ob ein Tumor gutartig oder bösartig ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Überblick verschaffen und Daten `Anmerkung(10): \"und\" entfernen:` und aufbereiten**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst sehen wir uns die Daten an, und bereiten diese dann für den Gebrauch der kNN - Klassifikation auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daten importieren\n",
    "wbcd <- read.table(file = \"data/wisc_bc_data.csv\", header = TRUE, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t569 obs. of  32 variables:\n",
      " $ id                     : int  842302 842517 84300903 84348301 84358402 843786 844359 84458202 844981 84501001 ...\n",
      " $ diagnosis              : Factor w/ 2 levels \"B\",\"M\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ radius_mean            : num  18 20.6 19.7 11.4 20.3 ...\n",
      " $ texture_mean           : num  10.4 17.8 21.2 20.4 14.3 ...\n",
      " $ perimeter_mean         : num  122.8 132.9 130 77.6 135.1 ...\n",
      " $ area_mean              : num  1001 1326 1203 386 1297 ...\n",
      " $ smoothness_mean        : num  0.1184 0.0847 0.1096 0.1425 0.1003 ...\n",
      " $ compactness_mean       : num  0.2776 0.0786 0.1599 0.2839 0.1328 ...\n",
      " $ concavity_mean         : num  0.3001 0.0869 0.1974 0.2414 0.198 ...\n",
      " $ concave.points_mean    : num  0.1471 0.0702 0.1279 0.1052 0.1043 ...\n",
      " $ symmetry_mean          : num  0.242 0.181 0.207 0.26 0.181 ...\n",
      " $ fractal_dimension_mean : num  0.0787 0.0567 0.06 0.0974 0.0588 ...\n",
      " $ radius_se              : num  1.095 0.543 0.746 0.496 0.757 ...\n",
      " $ texture_se             : num  0.905 0.734 0.787 1.156 0.781 ...\n",
      " $ perimeter_se           : num  8.59 3.4 4.58 3.44 5.44 ...\n",
      " $ area_se                : num  153.4 74.1 94 27.2 94.4 ...\n",
      " $ smoothness_se          : num  0.0064 0.00522 0.00615 0.00911 0.01149 ...\n",
      " $ compactness_se         : num  0.049 0.0131 0.0401 0.0746 0.0246 ...\n",
      " $ concavity_se           : num  0.0537 0.0186 0.0383 0.0566 0.0569 ...\n",
      " $ concave.points_se      : num  0.0159 0.0134 0.0206 0.0187 0.0188 ...\n",
      " $ symmetry_se            : num  0.03 0.0139 0.0225 0.0596 0.0176 ...\n",
      " $ fractal_dimension_se   : num  0.00619 0.00353 0.00457 0.00921 0.00511 ...\n",
      " $ radius_worst           : num  25.4 25 23.6 14.9 22.5 ...\n",
      " $ texture_worst          : num  17.3 23.4 25.5 26.5 16.7 ...\n",
      " $ perimeter_worst        : num  184.6 158.8 152.5 98.9 152.2 ...\n",
      " $ area_worst             : num  2019 1956 1709 568 1575 ...\n",
      " $ smoothness_worst       : num  0.162 0.124 0.144 0.21 0.137 ...\n",
      " $ compactness_worst      : num  0.666 0.187 0.424 0.866 0.205 ...\n",
      " $ concavity_worst        : num  0.712 0.242 0.45 0.687 0.4 ...\n",
      " $ concave.points_worst   : num  0.265 0.186 0.243 0.258 0.163 ...\n",
      " $ symmetry_worst         : num  0.46 0.275 0.361 0.664 0.236 ...\n",
      " $ fractal_dimension_worst: num  0.1189 0.089 0.0876 0.173 0.0768 ...\n"
     ]
    }
   ],
   "source": [
    "#Datenstruktur ansehen\n",
    "str(wbcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier sehen wir auch, dass der Datensatz 569 Beobachtungen und 32 Variablen hat.\n",
    "\n",
    "Die Patienen - ID ist für unser maschinelles Lernen nicht wichtig, sie ist lediglich ein eindeutiger Identifikator für die Patienten. Wir entfernen **`Anmerkung(11) -> \"diese\":`** dise Variable daher aus dem Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t569 obs. of  31 variables:\n",
      " $ diagnosis              : Factor w/ 2 levels \"B\",\"M\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ radius_mean            : num  18 20.6 19.7 11.4 20.3 ...\n",
      " $ texture_mean           : num  10.4 17.8 21.2 20.4 14.3 ...\n",
      " $ perimeter_mean         : num  122.8 132.9 130 77.6 135.1 ...\n",
      " $ area_mean              : num  1001 1326 1203 386 1297 ...\n",
      " $ smoothness_mean        : num  0.1184 0.0847 0.1096 0.1425 0.1003 ...\n",
      " $ compactness_mean       : num  0.2776 0.0786 0.1599 0.2839 0.1328 ...\n",
      " $ concavity_mean         : num  0.3001 0.0869 0.1974 0.2414 0.198 ...\n",
      " $ concave.points_mean    : num  0.1471 0.0702 0.1279 0.1052 0.1043 ...\n",
      " $ symmetry_mean          : num  0.242 0.181 0.207 0.26 0.181 ...\n",
      " $ fractal_dimension_mean : num  0.0787 0.0567 0.06 0.0974 0.0588 ...\n",
      " $ radius_se              : num  1.095 0.543 0.746 0.496 0.757 ...\n",
      " $ texture_se             : num  0.905 0.734 0.787 1.156 0.781 ...\n",
      " $ perimeter_se           : num  8.59 3.4 4.58 3.44 5.44 ...\n",
      " $ area_se                : num  153.4 74.1 94 27.2 94.4 ...\n",
      " $ smoothness_se          : num  0.0064 0.00522 0.00615 0.00911 0.01149 ...\n",
      " $ compactness_se         : num  0.049 0.0131 0.0401 0.0746 0.0246 ...\n",
      " $ concavity_se           : num  0.0537 0.0186 0.0383 0.0566 0.0569 ...\n",
      " $ concave.points_se      : num  0.0159 0.0134 0.0206 0.0187 0.0188 ...\n",
      " $ symmetry_se            : num  0.03 0.0139 0.0225 0.0596 0.0176 ...\n",
      " $ fractal_dimension_se   : num  0.00619 0.00353 0.00457 0.00921 0.00511 ...\n",
      " $ radius_worst           : num  25.4 25 23.6 14.9 22.5 ...\n",
      " $ texture_worst          : num  17.3 23.4 25.5 26.5 16.7 ...\n",
      " $ perimeter_worst        : num  184.6 158.8 152.5 98.9 152.2 ...\n",
      " $ area_worst             : num  2019 1956 1709 568 1575 ...\n",
      " $ smoothness_worst       : num  0.162 0.124 0.144 0.21 0.137 ...\n",
      " $ compactness_worst      : num  0.666 0.187 0.424 0.866 0.205 ...\n",
      " $ concavity_worst        : num  0.712 0.242 0.45 0.687 0.4 ...\n",
      " $ concave.points_worst   : num  0.265 0.186 0.243 0.258 0.163 ...\n",
      " $ symmetry_worst         : num  0.46 0.275 0.361 0.664 0.236 ...\n",
      " $ fractal_dimension_worst: num  0.1189 0.089 0.0876 0.173 0.0768 ...\n"
     ]
    }
   ],
   "source": [
    "#id löschen, indem die erste Spalte des wbcd Datensatzes gelöscht wird\n",
    "wbcd<-wbcd[-1]\n",
    "#Struktur betrachten\n",
    "str(wbcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die nächste Variable \"diagnosis\" ist für uns entscheident. Denn wir wollen genau dieses Resultat versuchen vorherzusagen. Zunächst schauen wir wie viele gutartige und bösartige Tumoren in dem Datensatz vorhanden sind. Über die `table()` - Funktion können wir dies untersuchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  B   M \n",
       "357 212 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(wbcd$diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt also 357 gutartige und 212 bösartige Tumoren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies kann auch als Anteil ausgegeben werden über die `prop.table()` - Funktion. \n",
    "Wir runden mit der `round()` - Funktion auf eine Nachkommastelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   B    M \n",
       "62.7 37.3 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "round(prop.table(table(wbcd$diagnosis))*100, digits =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle anderen Variablen sind **`Anmerkung(12) -> \"numerisch\":`** nurmerisch und bestehen, wie bereits beschrieben, aus drei Messwerten. Wir sehen uns als Beispiel drei Variablen genauer an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  radius_mean       area_mean      smoothness_mean  \n",
       " Min.   : 6.981   Min.   : 143.5   Min.   :0.05263  \n",
       " 1st Qu.:11.700   1st Qu.: 420.3   1st Qu.:0.08637  \n",
       " Median :13.370   Median : 551.1   Median :0.09587  \n",
       " Mean   :14.127   Mean   : 654.9   Mean   :0.09636  \n",
       " 3rd Qu.:15.780   3rd Qu.: 782.7   3rd Qu.:0.10530  \n",
       " Max.   :28.110   Max.   :2501.0   Max.   :0.16340  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(wbcd[c(\"radius_mean\", \"area_mean\", \"smoothness_mean\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie in der Einführung bereits beschrieben, ist  die Abstandsberechnung stark von der Skalierung der einzelnen Variablen abhängig. Der **`Anmerkung(13) -> sollte es nicht \"smoothness_mean\" heißen?:`** \"smothnes_mean\" (Mittelwert der Glätte) reicht von 0.05 bis zu 0.16, während der \"area_mean\" (Mittelwert der Fläche) von 143.5 bis 2501 reicht. Also wird der Einfluss der Flächenvariablen bei der Abstandsberechnung viel größer sein als der Einfluss der Glätte. Um die Merkmale vergleichbar zu machen, wird eine Transformation angewendet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anmerkung(14) -> Außerdem würde ich im Markdown die Variablennamen auch hervorheben, sieht meiner Meinung nach besser aus, aber ist dir überlassen :) Beispiel:** Die Variable `radius_mean` ist wichtig, da.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformation - numerische Daten normalisieren**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Merkmale zu normieren, wird eine `normalize()` - Funktion erstellt. Diese Funktion nimmt einen Vektor _x_ mit numerischen Werten entgegen. Für jeden Wert in _x_ wird der kleinste Wert von _x_ abgezogen und durch den Range von _x_ geteilt. Dann wird das Resultat als Vektor zurückgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize <- function(x){\n",
    "    return ((x-min(x)) / (max(x) -min(x)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem dieser Code ausgeführt wird, ist die Funktion für den Gebrauch verfügbar. Wir können testen, ob die Funktion korrekt ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>0.25</li>\n",
       "\t<li>0.5</li>\n",
       "\t<li>0.75</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0.25\n",
       "\\item 0.5\n",
       "\\item 0.75\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 0.25\n",
       "3. 0.5\n",
       "4. 0.75\n",
       "5. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.00 0.25 0.50 0.75 1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalize(c(1,2,3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>0.25</li>\n",
       "\t<li>0.5</li>\n",
       "\t<li>0.75</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0.25\n",
       "\\item 0.5\n",
       "\\item 0.75\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 0.25\n",
       "3. 0.5\n",
       "4. 0.75\n",
       "5. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.00 0.25 0.50 0.75 1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalize(c(10,20,30,40,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier ist folgendes gut zu erkennen: Obwohl der zweite Vektor zehn mal so groß ist wie der erste, sind sie nach der Normierung gleich."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir diese Funktion auf unseren Datensatz anwenden. Statt jeden der 30 Werte einzelnen zu normieren, werden wir die in R implementierte `lapply()` - Funktion verwenden. Diese Funktion nimmt eine Liste entgegen und wendet auf jedes der darin enthaltenen Elemente eine Funktion an. Da ein R - Dataframe eine Liste von gleich langen Vektoren ist, können wir die `lapply()` - Funktion nehmen um die `normalize()` - Funktion anzuwenden. Zuletzt müssen wir jedoch die Liste, die **`Anmerkung(15) -> \"dadurch\":`** dadruch zurück gegeben wird, wieder als Dataframe konvertieren. Dies geht über die `as.data.frame()` - Funktion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir brauchen die Funktion erst ab der zweiten Variable, da die erste \"diagnose\" ist\n",
    "wbcd_n <- as.data.frame(lapply(wbcd[2:31], normalize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun überprüfen wir, ob die Transformation richtig durchgeführt wurde, indem wir die Statistik einer Variablen betrachten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       " 0.0000  0.1174  0.1729  0.2169  0.2711  1.0000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(wbcd_n$area_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die \"area_mean\" Variable, die zuvor von 143.5 bis 2051 reichte, liegt nun zwischen 0 und 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lerndaten und Test - Datasets erstellen**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben 569 Beobachtungen, die bereits als gutartig bzw bösartig eingestuft sind. Wir teilen unsere Daten in zwei Teile:\n",
    "- einen Trainingsdatensatz, das verwendet wird um das kNN - Modell aufzustellen und\n",
    "- einen **`Anmerkung(16) -> \"TestDATENsatz\":`** Testdatasatz, das verwendet wird um zu schätzen wie genau die Voraussage ist\n",
    "\n",
    "Die ersten 469 Beobachtungen verwenden wir als Lerndaten und die anderen 100 um neue Patienten zu simulieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd_train <- wbcd_n[1:469, ] #Zeile 1 bis 469, alle Spalten als Trainingsdaten\n",
    "wbcd_test <- wbcd_n[470:569, ] #Zeile 470 bis 569, alle Spalten als Testdaten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hinweis**: Da unser Datensatz nicht sortiert war, ist sowohl der Trainingsdatensatz und der Testdatensatz repräsentativ für den gesamten Datensatz. Andernfalls wären Zufallsmethoden erforderlich. Beispielsweise, wenn das Dataset chronologisch sortiert ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als die Transformation durchgeführt wurde, wurde die Zielvariable (\"diagnosis\") nicht mitaufgenommen (Dataset wbcd_n). Um unser Modell zu trainieren, müssen wir diese Klassen in Vektoren, getrennt nach Lerndaten und Testdaten, speichern (vom Dataset wbcd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd_train_labels<-(wbcd[1:469, 1]) #Zeile 1 bis 469, die erste Spalte sind die Klassen des Trainingsdatensatzes\n",
    "wbcd_test_labels<-(wbcd[470:569, 1])#Zeile 470 bis 569, die erste Spalte sind die Klassen des Testdatensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Ein Modell erstellen**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da wir nun einen Traingsdatensatz und die Vektoren mit den Klassen haben, können wir die Klassen unserer Testdaten vom Modell vorhersagen lassen.\n",
    "\n",
    "Beim kNN - Algorithmus werden die eingegeben Daten lediglich in **`Anmerkung(17) -> \"struktuRiertem\":`** struktuiertem Format abgespeichert. Die Lernphase beinhaltet also nicht die Bildung eines Modells, weshalb er **`Anmerkung(18) -> \"gerade\":`** gearde darum auch als \"lazy learning\" (träges Lernen) bezeichnet wird.\n",
    "\n",
    "Um unsere Testdaten zu klassieren, laden wir das **package `class`** in R, das einige Grundfunktionen zur Klassifikation beinhaltet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'class' is in use and will not be installed\""
     ]
    }
   ],
   "source": [
    "install.packages(\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `knn()` - Funktion im `class` - Package bietet eine klassische Implementierung des kNN - Algorithmus. Für jedes Beispiel in den Testdaten, identifiziert die Funktion die k - nächsten Nachbarn, indem sie den Eukldischen Abstand misst. K wird vom Benutzer festgelegt. Das Beispiel wird der Klasse mit den meisten k nächsten Nachbarn zugeteilt. Hat eine Instanz gleich viele nächste Nachbarn von jeder Klasse, wird zufällig zugeteilt.\n",
    "\n",
    "Die `knn()` - Funktion wird in einem Funktionsaufruf unter dem Gebrauch von vier Parametern durchgeführt.\n",
    "\n",
    "`p <- knn(train, test, class, k)`\n",
    "\n",
    "- `train` ist der Trainingsdatensatz\n",
    "- `test` ist der Testdatensatz\n",
    "- `class` ist der Vektor mit den Klassen der Trainingsdaten\n",
    "- `k` gibt die Anzahl der nächsten Nachbarn an\n",
    "\n",
    "Die Funktion liefert einen Vektor mit der vorhergesagten Klasse für jede Zeile der Testdaten.\n",
    "\n",
    "Drei Parameter haben wir bereits. Es fehlt nur noch _k_, um die Anzahl der nächsten Nachbarn, zu denen der Abstand gemessen werden soll, festzulegen.\n",
    "\n",
    "Unser Lerndatensatz umfasst 469 Beobachtungen.  \n",
    "\n",
    "  $$\n",
    "  k= \\sqrt{469} = 21,65\n",
    "  $$\n",
    "  \n",
    "Wir erhalten gerundet die ungerade Zahl 21. Eine ungerade Zahl verhindert, dass sogenannte \"Bindungen\" (ties) entstehen. Das heißt, dass eine Instanz gleich vielen nächsten Nachbarn in jeder Klasse hat und damit nicht eindeutig klassifiziert werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"class\")\n",
    "wbcd_test_pred <- knn(train=wbcd_train, test = wbcd_test, cl = wbcd_train_labels, k=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun ist ein Vektor mit vorhergesagten Klassen für alle Beispiele der Testdaten in `wbcd_test_pred` gespeichert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Die Leistung des Modells beurteilen**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schließlich muss überprüft werden wie gut die vorhergesagten Klassen der Testdaten von `wbcd_test_pred` mit den tatsächlichen Klassen der Testdaten, die wir im Vektor `wbcd_test_label` gespeichert haben, übereinstimmen. Dafür verwenden wir die **`Anmerkung(19) -> \"CrossTable\":`**`CorssTable()` - Funktion aus dem `gmodels` Package um eine Kreuztabelle darzustellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependencies 'gtools', 'gdata'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'gtools' successfully unpacked and MD5 sums checked\n",
      "package 'gdata' successfully unpacked and MD5 sums checked\n",
      "package 'gmodels' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\HS\\AppData\\Local\\Temp\\RtmpmkwLCB\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"gmodels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(gmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "   Cell Contents\n",
      "|-------------------------|\n",
      "|                       N |\n",
      "| Chi-square contribution |\n",
      "|           N / Row Total |\n",
      "|           N / Col Total |\n",
      "|         N / Table Total |\n",
      "|-------------------------|\n",
      "\n",
      " \n",
      "Total Observations in Table:  100 \n",
      "\n",
      " \n",
      "                 | wbcd_test_pred \n",
      "wbcd_test_labels |         B |         M | Row Total | \n",
      "-----------------|-----------|-----------|-----------|\n",
      "               B |        77 |         0 |        77 | \n",
      "                 |     4.298 |    16.170 |           | \n",
      "                 |     1.000 |     0.000 |     0.770 | \n",
      "                 |     0.975 |     0.000 |           | \n",
      "                 |     0.770 |     0.000 |           | \n",
      "-----------------|-----------|-----------|-----------|\n",
      "               M |         2 |        21 |        23 | \n",
      "                 |    14.390 |    54.134 |           | \n",
      "                 |     0.087 |     0.913 |     0.230 | \n",
      "                 |     0.025 |     1.000 |           | \n",
      "                 |     0.020 |     0.210 |           | \n",
      "-----------------|-----------|-----------|-----------|\n",
      "    Column Total |        79 |        21 |       100 | \n",
      "                 |     0.790 |     0.210 |           | \n",
      "-----------------|-----------|-----------|-----------|\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "CrossTable(x= wbcd_test_labels, y=wbcd_test_pred, prob.chisq = FLASE) \n",
    "#mit prob.chisq = FALSE werden die CHI^2 - Werte nicht angezeigt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Tabelle zeigt die Werte in vier Kategorien. Oben links sind die 77 Werte, die gutartig (B) sind und vom kNN - Algorithmus auch als solche erkannt wurden (true negative, _negativ in diesem Fall, da es ein medizinischer Test ist. Wenn dieser negativ ausfällt, so liegt die getestete Krankheit nicht vor_). Unten rechts werden die Werte angezeigt, die als bösartig eingestuft werden (M) und vom kNN - Algorithmus auch als solche klassifiziert wurden (true positive). Die anderen beiden Zellen zeigen, wo der kNN - Algorithmus keine Übereinstimmung mit den wahren Werten hat. Also in diesem Fall die zwei unten links, bei denen der Tumor als gutartig eingestuft wurde, tatsächlich aber bösartig ist (false negative).\n",
    "\n",
    "Fehler auf dem medizinischen Gebiet können fatal und kostspielig sein. Es würde dazu führen, dass die Krankheit einer Person, die einen bösartigen Tumor hat, als gutartig eingestuft wird. Somit könnte der Krebs weiter streuen. Andersherum würde eine \"false - positive\" eigestufte Person behandelt werden, obwohl sie keinen bösartigen Tumor hat.\n",
    "\n",
    "Es gibt verschiedene Methoden, Fehlerraten zu optimieren. Dies ist jedoch ein extra Kapitel, welches [in Kaptiel 10 diesen Buches](https://www.packtpub.com/big-data-and-business-intelligence/machine-learning-r) genauer erläutert wird.\n",
    "\n",
    "2% sind also nur falsch eingestuft worden. 98% Genauigkeit ist sehr gut. Auf diesem sensiblen Gebiet jedoch sollte die Performance verbessert werden, insbesondere die falsch negativen Ergebnisse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Die Modell - Performance verbessern**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir werden zwei Varianten unserer vorangegangenen Klassifikation versuchen. Zunächst kann man eine andere Methode für die Transformation der Skalierung verwenden. Außerdem kann man andere Werte für _k_ testen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**die z-Transformation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die zunächst durchgeführte Normierung der Skalierung ist die übliche Vorgehensweise bei der **`Anmerkung(20) -> \"kNN()\"?:`** knn() - Klassifiakation. Sie passt jedoch nicht immer. Bei der z - Transformation gibt es keine vordefinierten Maximum und Minimum, also werden Extremwerte auch nicht ins Zentrum \"gedrückt\". Dies könnte bei der Tumorklassifikation auch ganz passend sein, denn ein bösartiger Tumor kann unkontrolliert wachsen und deshalb durchaus Ausreißer haben, die stärker gewichtet werden sollten in der Abstandsberechnung. \n",
    "\n",
    "Es gibt in R bereits eine Funktion `scale()` , die die z - Transformation direkt auf einen Dataframe anwendet. Wir werden nun alle Variablen, außer \"diagnosis\" neu skalieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbcd_z<- as.data.frame(scale(wbcd[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir überprüfen ob dies geklappt hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "-1.4532 -0.6666 -0.2949  0.0000  0.3632  5.2459 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(wbcd_z$area_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Mittelwert einer z-Transformation ist immer 0. Das Intervall sollte kompakt sein. Werte außerhalb von -3 bis 3 sind äußerst selten. Das Maximum von 5.24 könnte bei einem Tumor tatsächlich ein Ausreißer sein, der so vorkommt. Deshalb scheint obige Transformation annehmbar.\n",
    "\n",
    "Nun muss der Datensatz wieder in einen Trainingsdatensatz und einen Testdatensatz unterteilt und anschließend der kNN - Algorithmus agewandt werden. Die vorhergesagten Werte werden zuletzt wieder mit den tatsächlichen in einer **`Anmerkung(21) -> \"Kreuztabelle\":`** Kreutabelle verglichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "   Cell Contents\n",
      "|-------------------------|\n",
      "|                       N |\n",
      "|           N / Row Total |\n",
      "|           N / Col Total |\n",
      "|         N / Table Total |\n",
      "|-------------------------|\n",
      "\n",
      " \n",
      "Total Observations in Table:  100 \n",
      "\n",
      " \n",
      "                 | wbcd_test_pred \n",
      "wbcd_test_labels |         B |         M | Row Total | \n",
      "-----------------|-----------|-----------|-----------|\n",
      "               B |        77 |         0 |        77 | \n",
      "                 |     1.000 |     0.000 |     0.770 | \n",
      "                 |     0.975 |     0.000 |           | \n",
      "                 |     0.770 |     0.000 |           | \n",
      "-----------------|-----------|-----------|-----------|\n",
      "               M |         2 |        21 |        23 | \n",
      "                 |     0.087 |     0.913 |     0.230 | \n",
      "                 |     0.025 |     1.000 |           | \n",
      "                 |     0.020 |     0.210 |           | \n",
      "-----------------|-----------|-----------|-----------|\n",
      "    Column Total |        79 |        21 |       100 | \n",
      "                 |     0.790 |     0.210 |           | \n",
      "-----------------|-----------|-----------|-----------|\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "wbcd_train <- wbcd_z[1:469, ] #Aufteilung in Trainingsdaten\n",
    "wbcd_test <- wbcd_z[470:569, ] # Aufteilung in Testdaten\n",
    "# wahren Klassen in einem Vektor speichern\n",
    "wbcd_train_labels<-wbcd[1:469, 1] \n",
    "wbcd_test_labels<-wbcd[470:569, 1]\n",
    "# kNN - Klassifikation anwenden\n",
    "wbcd_test_pred <- knn(train=wbcd_train, test = wbcd_test, cl = wbcd_train_labels, k =21)\n",
    "# Überprüfung wie viel Übereinstimmung der vorhergesagten mit den tatsächlichen Klassen\n",
    "CrossTable(x= wbcd_test_labels, y = wbcd_test_pred, prop.chisq = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der z-Transformation konnte leider keine höhere Genauigkeit erzielt werden. Es werden immer noch zwei Fälle für als falsch eingestuft. 98% sind richtig eingestuft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**andere Werte für k testen**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können nun das \"Modell\" oben mit verschiedenen k - Werten testen, bis unser Modell noch genauer als 98 % wird. Dabei ist jedoch zu beachten, dass das \"Modell\" evtl. zu sehr auf unsere Testdaten angepasst wird und kann vielleicht nicht mehr passend für andere Daten ist. Um sicher zu gehen, dass ein Modell verallgemeinert werden kann, sollte man seinen Datensatz wiederholt in zufällig zusammengestellte Testdatensätze aufteilen und testen. Die Tabelle zeigt die verschiedenen Werte für k:\n",
    "\n",
    " k | #false negative | #false positive | falsch klassifiziert in % \n",
    "  :-----------------:|:---------------:|:-------------------------:|\n",
    " 1 |     1           |      3          |   4                       |            \n",
    " 5 |     2           |      0          |   2                       | \n",
    "11 |     3           |      0          |   3                       |      \n",
    "15 |     3           |      0          |   3                       |      \n",
    "21 |     2           |      0          |   2                       |    \n",
    "27 |     4           |      0          |   4                       |     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen also, dass k=21 ganz gut ist. Bei k = 1 konnte allerdings verhindert werden, dass **`Anmerkung(22) -> \"Grammatik\":`** eine Patienten, die einen bösartigen Tumor hat, als gutartig eingestuft wurde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anmerkung(23) -> Deine Ausarbeitung ist sehr gut gelungen. Habe auch soweit alles verstanden. \n",
    "Ich würde aber noch einige Formatsänderungen durchführen, um eine Vereinheitlichung zu garantieren, damit die Ausarbeitung auch schöner ausschaut. Beispielsweise hast du oft mal \"k - Werten\" und mal \"k-Werten\", oder \"x=y\" bzw. \"x = y\" stehen. Ich weiß zu pingelig sollte man auch nicht sein, aber ist ja auch nur ein Tipp von mir.\n",
    "Viele Grüße, \n",
    "Faruk :)) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
